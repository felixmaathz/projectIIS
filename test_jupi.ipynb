{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from furhat_remote_api import FurhatRemoteAPI\n",
    "import speech_recognition as sr\n",
    "import cv2\n",
    "import opencv_jupyter_ui as jcv2\n",
    "from feat.utils import FEAT_EMOTION_COLUMNS\n",
    "from feat import Detector\n",
    "from train_model import train_model\n",
    "\n",
    "# Detector choice\n",
    "model = train_model()\n",
    "detector = Detector(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Furhat IP address\n",
    "FURHAT_IP = \"127.0.1.1\"\n",
    "\n",
    "# Connect to Furhat\n",
    "furhat = FurhatRemoteAPI(FURHAT_IP)\n",
    "furhat.set_led(red=100, green=50, blue=50)\n",
    "\n",
    "# Furhat faces and voices\n",
    "FACES = {'Bartender': 'Brooklyn'}\n",
    "VOICES_EN = {'Bartender': 'GregoryNeural'}\n",
    "\n",
    "emotion_detection_active = False\n",
    "\n",
    "# Function to start emotion detection\n",
    "def start_emotion_detection():\n",
    "    global emotion_detection_active\n",
    "    emotion_detection_active = True\n",
    "\n",
    "# Function to stop emotion detection\n",
    "def stop_emotion_detection():\n",
    "    global emotion_detection_active\n",
    "    emotion_detection_active = False\n",
    "\n",
    "# Furhat speech\n",
    "def bsay(line):\n",
    "    furhat.say(text=line, blocking=True)\n",
    "    sleep(1) \n",
    "\n",
    "# Speech recognition setup\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Function to recognize speech\n",
    "def recognize_speech():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something!\")\n",
    "        audio = recognizer.listen(source, timeout=5)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"You said:\", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech Recognition could not understand audio.\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Function for emotion detection\n",
    "def detect_emotion(frame):\n",
    "    faces = detector.detect_faces(frame)\n",
    "    landmarks = detector.detect_landmarks(frame, faces)\n",
    "    emotions = detector.detect_emotions(frame, faces, landmarks)\n",
    "\n",
    "    faces = faces[0]\n",
    "    emotions = emotions[0]\n",
    "\n",
    "    strongest_emotion = emotions.argmax(axis=1)\n",
    "\n",
    "    for (face, top_emo) in zip(faces, strongest_emotion):\n",
    "        (x0, y0, x1, y1, p) = face\n",
    "        cv2.rectangle(frame, (int(x0), int(y0)), (int(x1), int(y1)), (255, 0, 0), 3)\n",
    "        cv2.putText(frame, FEAT_EMOTION_COLUMNS[top_emo], (int(x0), int(y0 - 10)),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 0, 0), 2)\n",
    "        \n",
    "        print(f\"Detected emotion: {FEAT_EMOTION_COLUMNS[top_emo]}\")\n",
    "        # Return the detected emotion\n",
    "        return FEAT_EMOTION_COLUMNS[top_emo] \n",
    "\n",
    "\n",
    "# Function to react to speech\n",
    "def speech(text):\n",
    "    if text:\n",
    "        if \"hello\" in text.lower():\n",
    "            bsay(\"very tasty\")\n",
    "            furhat.gesture(name='Surprise')\n",
    "\n",
    "# Function to react to emotion\n",
    "def emotion(detected_emotion):\n",
    "        \n",
    "            print(f\"Detected emotion: {detected_emotion}\")\n",
    "            if detected_emotion == \"happiness\":\n",
    "                bsay(\"You are happy\")\n",
    "                furhat.gesture(name=\"Smile\")\n",
    "            elif detected_emotion == \"sadness\":\n",
    "                bsay(\"You are sad\")\n",
    "                furhat.gesture(name='Oh')\n",
    "            elif detected_emotion == \"neutral\":\n",
    "                bsay(\"You are neutral\")\n",
    "                furhat.gesture(name='Wink')\n",
    "\n",
    "# Interaction function\n",
    "def interaction():\n",
    "    furhat.set_face(character=FACES['Bartender'], mask=\"Adult\")\n",
    "    furhat.set_voice(name=VOICES_EN['Bartender'])\n",
    "    bsay(\"Hi\")\n",
    "    furhat.gesture(name='BigSmile')\n",
    "\n",
    "    global emotion_detection_active\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Error: failed to capture image\")\n",
    "            break\n",
    "\n",
    "        if emotion_detection_active:\n",
    "            detected_emotion = detect_emotion(frame)\n",
    "            emotion(detected_emotion)\n",
    "\n",
    "        speech_text = recognize_speech()\n",
    "        if speech_text:\n",
    "            print(f\"Recognized: {speech_text}\")\n",
    "            if \"start\" in speech_text.lower():\n",
    "                start_emotion_detection()\n",
    "                bsay(\"Emotion detection started\")\n",
    "            elif \"stop\" in speech_text.lower():\n",
    "                stop_emotion_detection()\n",
    "                bsay(\"Emotion detection stopped\")\n",
    "\n",
    "\n",
    "        \n",
    "        jcv2.imshow(\"Emotion Detection\", frame)\n",
    "        key = jcv2.waitKey(33) & 0xFF\n",
    "        if key == 27:  # ESC pressed\n",
    "            break\n",
    "\n",
    "# Set up camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "# main function\n",
    "if __name__ == '__main__':\n",
    "    interaction()\n",
    "\n",
    "cam.release()\n",
    "jcv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
